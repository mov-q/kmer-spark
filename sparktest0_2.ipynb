{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sparktest0.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrfDpobC10bMAjHFO7xOTr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mov-q/kmer-spark/blob/main/sparktest0_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIHw-XHZU5-G"
      },
      "source": [
        "# K-mer counting con pySpark #\n",
        "\n",
        "### Introduzione al problema ###\n",
        "Negli ultimi anni gli avanzamenti nell'ambito della bioinformatica sono spesso stati identificabili e ascrivibili ai grandi avanzamenti delle tecnologie di sequenziamento: il sequenziamento è l'operazione attraverso la quale, a partire da un campione biologico, è possibile andare ad estrarre la sequenza di DNA (genoma) o RNA (trascrittoma). \n",
        "\n",
        "Con l'affermarsi delle tecnologie NGS (Next Generation Sequencing), l'approccio tecnologico che si è affermato è quello di sequenze che vengono lette in forma di short reads: centinaia di migliaia (nel caso di piccoli genomi batterici) o decine di milioni di stringhe di dimensione più o meno variabile. Una delle maggiori sfide dal punto di vista computazionale è quella di generare un \"assembly\" del genoma o del trascrittoma: andare ad unire queste stringhe per ricostruire la sequenza reale.\n",
        "\n",
        "Tra le tecniche degli algoritmi di assembly, quella prevalente è basata sulla generazione, a partire dalle short reads, di k-mer: sottostringhe di k basi nucleotidiche calcolate da ogni read utilizzando una sliding window di dimensione k e a partire dal primo carattere. \n",
        "\n",
        "La pipeline completa di processamento prevede delle fasi di trimming degli adapter (sequenze utilizzate dai kit di preparamento campioni sperimentali), analisi di qualità delle short-reads (e ad esempio delezione delle sequenze troppo corte o di qualità troppo bassa), generazione dei k-mer dalle reads e conteggio delle occorrenze di ogni k-mer. \n",
        "\n",
        "Tutti questi passaggi sono il preambolo alla creazione di una struttura grafo (grafo di de Brujin) che viene poi utilizzata come base per l'assembly definitivo del genoma (o di frammenti di esso, come singoli contigs e scaffolds). \n",
        "\n",
        "### Il progetto ###\n",
        "Questo progetto si propone di implementare attraverso l'uso di Spark, più precisamente dei wrapper python pySpark, un k-mer counter che a partire da un file in formato FASTQ vada ad effettuare estrazione delle sequenze, una pulizia piuttosto grezza (data solo ai fini di esempio di trattamento del formato), la generazione dei k-mer e il conto delle loro occorrenze. \n",
        "Al contempo, al termine di questa fase di conto occorrenze, avremo anche per ogni sequenza il calcolo dei prefissi e dei suffissi del k-mer generato, elementi fondamentali per poter costruire il grafo di De Brujin. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpnW6ZbvGWpa",
        "outputId": "c135c067-2e59-43e7-87da-5905a72459ad"
      },
      "source": [
        "import os\n",
        "import subprocess\n",
        "import string\n",
        "import random\n",
        "\n",
        "# settiamo il k-mer size\n",
        "KSIZE=55\n",
        "# definiamo se stiamo usando un dataset \"brief\" o se scaricheremo intere run da \n",
        "# NCBI SRA \n",
        "BRIEF=True\n",
        "# indichiamo quante run vogliamo processare\n",
        "# 0 significa che il file di input verrà processato interamente\n",
        "BRIEF_MULTIPLIER=0\n",
        "BRIEF_NOSEQ=4*BRIEF_MULTIPLIER\n",
        "# id delle run da scaricare da NCBI SRA (in caso che BRIEF sia settato a False)\n",
        "sraRunIDlist = [\"SRR16693264\", \"SRR16693265\"]\n",
        "# binari dello sratoolkit utilizzati per estrarre i file fastq dal formato binario sra\n",
        "PREFETCH_BASEPATH=\"/content\"\n",
        "NCBI_PREFETCH_BIN=\"/content/sratoolkit.2.11.2-ubuntu64/bin/prefetch-orig.2.11.2\"\n",
        "NCBI_FASTQDUMP_BIN=\"/content/sratoolkit.2.11.2-ubuntu64/bin/fastq-dump-orig.2.11.2\"\n",
        "\n",
        "# calcoliamo una stringa casuale da aggiungere come suffisso al percorso di output\n",
        "def generateRandomOutputSuffix(suff_length):\n",
        "  temp = random.sample(string.ascii_letters,suff_length)\n",
        "  return \"\".join(temp)\n",
        "\n",
        "OUTPUT_SUFFIX = generateRandomOutputSuffix(4)\n",
        "OUTPUT_PATH = \"/content/output_\"+OUTPUT_SUFFIX\n",
        "print(\"Output path: \"+OUTPUT_PATH)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output path: /content/output_jhFe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfbabOFW1Apd"
      },
      "source": [
        "exMemory = '10g'\n",
        "PYSPARK_SUBMIT_ARGS = ' --driver-memory ' + exMemory + ' pyspark-shell --driver-maxResultSize 10g'\n",
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = PYSPARK_SUBMIT_ARGS"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3NUJaxuehf_"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwuOKfO_eq_C"
      },
      "source": [
        "if (os.path.exists('spark-3.2.0-bin-hadoop3.2.tgz') == False):\n",
        "  !wget  https://downloads.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "  !tar xf spark-3.2.0-bin-hadoop3.2.tgz"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3nWns-PMPOB"
      },
      "source": [
        "if (os.path.exists('sratoolkit.2.11.2-ubuntu64.tar.gz') == False):\n",
        "  !wget  https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/2.11.2/sratoolkit.2.11.2-ubuntu64.tar.gz\n",
        "  !tar xf sratoolkit.2.11.2-ubuntu64.tar.gz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlLmIPdffuzD"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRUmxk3od2UF"
      },
      "source": [
        "if (os.path.exists(\"/content/inputbrief\") == False):\n",
        "  !mkdir /content/inputbrief\n",
        "  !wget -O brief.fastq.gz https://sra-download.ncbi.nlm.nih.gov/traces/sra57/SRZ/016777/SRR16777190/MD_2_D8.r1.fastq.gz \n",
        "  !gunzip brief.fastq.gz\n",
        "if BRIEF_NOSEQ == 0:\n",
        "  !cp brief.fastq /content/inputbrief/brief.fastq\n",
        "else:\n",
        "  !head -n $BRIEF_NOSEQ  brief.fastq > /content/inputbrief/brief.fastq\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df8FfE0pf0Fv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "abe67fb2-3034-4b96-ddb5-ed4a55448b10"
      },
      "source": [
        "# setup variabili d'ambiente\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop3.2\"\n",
        "from pathlib import Path\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "# verifica delle variabili d'ambiente\n",
        "findspark.find()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.2.0-bin-hadoop3.2'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9RDvm9OLMuV"
      },
      "source": [
        "\n",
        "\n",
        "def downloadFastq(runList):\n",
        "  for singleId in runList:\n",
        "    if os.path.exists(PREFETCH_BASEPATH+'/'+singleId):\n",
        "      print(\"Prefetch delle run già completato\")\n",
        "    else:\n",
        "      ncbiPrefetchProc = NCBI_PREFETCH_BIN + ' ' + singleId\n",
        "      print(\"Eseguo prefetch: \" + ncbiPrefetchProc)\n",
        "      subprocess.check_call(ncbiPrefetchProc, shell=True)\n",
        "      #ncbiFastqDump = \"/content/sratoolkit.2.11.2-ubuntu64/bin/fastq-dump-orig.2.11.2 --outdir /content/input/fastq/ --gzip --skip-technical  --readids --read-filter pass --dumpbase --split-3 --clip /content/\" + singleId + \"/\"+singleId+\".sra\"\n",
        "      ncbiFastqDumpProc = NCBI_FASTQDUMP_BIN+\" --outdir /content/input/fastq/ --skip-technical  --readids --read-filter pass --dumpbase --split-3 --clip /content/\" + singleId + \"/\"+singleId+\".sra\"\n",
        "      subprocess.check_call(ncbiFastqDumpProc, shell=True)\n",
        "\n",
        "if not BRIEF:\n",
        "  downloadFastq(sraRunIDlist)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlZhr3gBgb_4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "b6ecb127-e0e1-457b-afef-8b25b6649efc"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import col, lit\n",
        "import pyspark.sql.functions as func\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master('local')\\\n",
        "        .appName('km-ark')\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .config('spark.driver.maxResultSize', '10G')\\\n",
        "        .getOrCreate()\n",
        "\n",
        "spark"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c3cb4539a588:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>km-ark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fe730780c10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbIWGWxBY8Cw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea0d885-3a92-4222-8703-6a9fd1fc5275"
      },
      "source": [
        "if not BRIEF:\n",
        "  datasetPath = Path(\"/content/input/fastq/\")\n",
        "  datasetFiles = [str(sf) for sf in datasetPath.iterdir()]\n",
        "else:\n",
        "  datasetPath = Path(\"/content/inputbrief/\")\n",
        "  datasetFiles = [str(sf) for sf in datasetPath.iterdir()]\n",
        "\n",
        "print(\"File in input: \", len(datasetFiles))\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "# read data from text file and split each line into words\n",
        "#words = sc.textFile(\"/content/input.txt\").flatMap(lambda line: line.split(\" \"))\n",
        "\n",
        "def preProcess(s):\n",
        "  return s\n",
        "\n",
        "def stripFastQ(s):\n",
        "  if (s[0] != '@') and (s[0] != '+'):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "#rowDataFrame = sc.textFile(','.join(datasetFiles)).\\\n",
        "#                  map(lambda x: Row(row=stripId(x))).\\\n",
        "#                  zipWithIndex().\\\n",
        "#                  toDF([\"fastqRow\",\"index\"])\n",
        "\n",
        "# per ritornare tuple:    map(lambda x: (preProcess(x),1)).\\\n",
        "rawData = None\n",
        "\n",
        "rawData = sc.textFile(','.join(datasetFiles)).zipWithIndex()\n",
        "#rawData.collect()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File in input:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERTMhpU5XTim",
        "outputId": "ca90bcb9-1d8a-4ffa-ae80-885bc8568b3f"
      },
      "source": [
        "\n",
        "\n",
        "#filtered = rowData.filter(lambda line: stripFastQ(line)).collect()\n",
        "rawDataFrame = rawData.map(lambda line: preProcess(line)).toDF([\"fastqRow\",\"index\"])\n",
        "rawDataFrame.show(truncate=False)\n",
        "# aggiungiamo una chiave per il raggruppamento in 4 righe\n",
        "gSeq = rawDataFrame.withColumn(\"group\", col(\"index\")/4)\n",
        "gSeq = gSeq.withColumn(\"group\", col(\"group\").cast(IntegerType()))\n",
        "# mostriamo il dataframe risultante\n",
        "gSeq.show(truncate=False)\n",
        "gSeqRDD = gSeq.rdd\n",
        "#gSeqRDD.collect()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|fastqRow                                                                                                                                               |index|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|@A00152:72:HFKKWDSXX:1:1101:24632:1000 1:N:0:0                                                                                                         |0    |\n",
            "|CTTATAAGCTCAATGGTGTTTTCCACCGTGATCCGCCGCTGACGCAGCGTGCTCTCAAATATCTGCCGGAAGACACATTGCGGTTCGTTGATAATAAAGCTACAGGCGTTATGTCTTCCCGGCTCAGTAAAATCGACATCTGCAATTTGCG|1    |\n",
            "|+                                                                                                                                                      |2    |\n",
            "|,FFFFFFF:FFFFF,FFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFF,FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFF,FFF:FFFFFFFFFFFFFFFFFFF:FFFFF:F|3    |\n",
            "|@A00152:72:HFKKWDSXX:1:1101:30183:1000 1:N:0:0                                                                                                         |4    |\n",
            "|AACCTACAGTGAAAACCTGCTAATGCTGACGCTCTCTCGCGGTGGACCGATTGTCTGGATCAGCGAAACAGATGCCCGAGAACTGACCATTGTCGATAACGACTGGGTGGAAGTATTCAACGCCAACGGCGCGCTGACTGCCCGCGCGGTG|5    |\n",
            "|+                                                                                                                                                      |6    |\n",
            "|:FF,FFFFF:FFFFFFFFFFF,FFFF,FFFFFFFFFFF,FF:FFFFFFFF:FFFFFFFFFFFFFFFFFFF:FFFFF:FFF,FFFFFFFFF,F:FFFFFFFFF:FFFF,FF:FFFF,FFF:FFF,F:F:FFFFFFFF:F,FFFFFFFF:FFF|7    |\n",
            "|@A00152:72:HFKKWDSXX:1:1101:10791:1016 1:N:0:0                                                                                                         |8    |\n",
            "|GACATACAGGAAGAAATCGATCTTCAGACCCTTGTTAACGATGCGATGGCGGAGTTTCAGGGCATTCATCAGGACATGGTTAAGGCTGAGCAACAGCGTCAGCAGGAAAAAGAACGGCAGCGACTCGCCGAGCAGAAACGACAAAAGTCCG|9    |\n",
            "|+                                                                                                                                                      |10   |\n",
            "|FF:F:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFF:FFFFFFFFF:FFFFFFF,FFFFF,FFFFFFFFFFFFFFFFF:FFFFFF:FFFF:FFFFFFFFFFFFFFFFF:FFFFF:FFFFFFFFFFFFFF|11   |\n",
            "|@A00152:72:HFKKWDSXX:1:1101:19443:1031 1:N:0:0                                                                                                         |12   |\n",
            "|GTATAATTCCAGTTATATATTTTCGATTACCGAAGTCGCTACATTAGGGGGTTTATTATTTTGCTACGACACCGCCGTTATTTCCGGTACTGTTGAGTCACTCAATACCGTCTTTGTTGCTCCACAAAAATTAAGTGAATCAGCTGCCAAC|13   |\n",
            "|+                                                                                                                                                      |14   |\n",
            "|::F,F,FF,,F:,FF,FFF,FFFFFFFFFFF,,,F,::FFFFF,FF,F:FFF:,FFF,F:F,:,::FFFFF:FFF,::F,FFF:F,,FFF,F,FF:FFF:,FFFFF:F,,F,,F:F::FF,,F:FFFFF,,,FF,,,F::F,FF::F:FFF|15   |\n",
            "|@A00152:72:HFKKWDSXX:1:1101:7862:1047 1:N:0:0                                                                                                          |16   |\n",
            "|GGTGATCATCTCAACTTCTTCGCCAAAGCGGTTAATGGTACGACCCGGCACGGTAATGCTGGAGGTCGGTTTCAGCGCCATATGGGCAATGATTTGCTGCCCGCTGCTGATACCGCCGAGAATGCCGCCCGCATGGTTGCTCTGGAAACCG|17   |\n",
            "|+                                                                                                                                                      |18   |\n",
            "|FFFF,FF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,FFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFF::FFFFF:FFFFFF,FFFF|19   |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----+\n",
            "|fastqRow                                                                                                                                               |index|group|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----+\n",
            "|@A00152:72:HFKKWDSXX:1:1101:24632:1000 1:N:0:0                                                                                                         |0    |0    |\n",
            "|CTTATAAGCTCAATGGTGTTTTCCACCGTGATCCGCCGCTGACGCAGCGTGCTCTCAAATATCTGCCGGAAGACACATTGCGGTTCGTTGATAATAAAGCTACAGGCGTTATGTCTTCCCGGCTCAGTAAAATCGACATCTGCAATTTGCG|1    |0    |\n",
            "|+                                                                                                                                                      |2    |0    |\n",
            "|,FFFFFFF:FFFFF,FFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFF,FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFF,FFF:FFFFFFFFFFFFFFFFFFF:FFFFF:F|3    |0    |\n",
            "|@A00152:72:HFKKWDSXX:1:1101:30183:1000 1:N:0:0                                                                                                         |4    |1    |\n",
            "|AACCTACAGTGAAAACCTGCTAATGCTGACGCTCTCTCGCGGTGGACCGATTGTCTGGATCAGCGAAACAGATGCCCGAGAACTGACCATTGTCGATAACGACTGGGTGGAAGTATTCAACGCCAACGGCGCGCTGACTGCCCGCGCGGTG|5    |1    |\n",
            "|+                                                                                                                                                      |6    |1    |\n",
            "|:FF,FFFFF:FFFFFFFFFFF,FFFF,FFFFFFFFFFF,FF:FFFFFFFF:FFFFFFFFFFFFFFFFFFF:FFFFF:FFF,FFFFFFFFF,F:FFFFFFFFF:FFFF,FF:FFFF,FFF:FFF,F:F:FFFFFFFF:F,FFFFFFFF:FFF|7    |1    |\n",
            "|@A00152:72:HFKKWDSXX:1:1101:10791:1016 1:N:0:0                                                                                                         |8    |2    |\n",
            "|GACATACAGGAAGAAATCGATCTTCAGACCCTTGTTAACGATGCGATGGCGGAGTTTCAGGGCATTCATCAGGACATGGTTAAGGCTGAGCAACAGCGTCAGCAGGAAAAAGAACGGCAGCGACTCGCCGAGCAGAAACGACAAAAGTCCG|9    |2    |\n",
            "|+                                                                                                                                                      |10   |2    |\n",
            "|FF:F:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFF:FFFFFFFFF:FFFFFFF,FFFFF,FFFFFFFFFFFFFFFFF:FFFFFF:FFFF:FFFFFFFFFFFFFFFFF:FFFFF:FFFFFFFFFFFFFF|11   |2    |\n",
            "|@A00152:72:HFKKWDSXX:1:1101:19443:1031 1:N:0:0                                                                                                         |12   |3    |\n",
            "|GTATAATTCCAGTTATATATTTTCGATTACCGAAGTCGCTACATTAGGGGGTTTATTATTTTGCTACGACACCGCCGTTATTTCCGGTACTGTTGAGTCACTCAATACCGTCTTTGTTGCTCCACAAAAATTAAGTGAATCAGCTGCCAAC|13   |3    |\n",
            "|+                                                                                                                                                      |14   |3    |\n",
            "|::F,F,FF,,F:,FF,FFF,FFFFFFFFFFF,,,F,::FFFFF,FF,F:FFF:,FFF,F:F,:,::FFFFF:FFF,::F,FFF:F,,FFF,F,FF:FFF:,FFFFF:F,,F,,F:F::FF,,F:FFFFF,,,FF,,,F::F,FF::F:FFF|15   |3    |\n",
            "|@A00152:72:HFKKWDSXX:1:1101:7862:1047 1:N:0:0                                                                                                          |16   |4    |\n",
            "|GGTGATCATCTCAACTTCTTCGCCAAAGCGGTTAATGGTACGACCCGGCACGGTAATGCTGGAGGTCGGTTTCAGCGCCATATGGGCAATGATTTGCTGCCCGCTGCTGATACCGCCGAGAATGCCGCCCGCATGGTTGCTCTGGAAACCG|17   |4    |\n",
            "|+                                                                                                                                                      |18   |4    |\n",
            "|FFFF,FF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,FFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFF::FFFFF:FFFFFF,FFFF|19   |4    |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DMy_vKZhX-W"
      },
      "source": [
        "gSeqRDDgroup = gSeqRDD.map(lambda line: (line.group, (line.fastqRow, line.index)))\n",
        "#gSeqRDDgroup.collect()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1DvPLF_6B8t"
      },
      "source": [
        "seqGroups = gSeqRDDgroup.groupByKey()\n",
        "\n",
        "def setScoreDict():\n",
        "\n",
        "  valString = \"!\\\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\"\n",
        "  valDict = {}\n",
        "  idx = 0\n",
        "  for symbol in valString:\n",
        "    valDict[symbol] = len(valString)-idx\n",
        "    idx = idx+1\n",
        "\n",
        "  return valDict\n",
        "  \n",
        "scoreTable = setScoreDict()\n",
        "\n",
        "def parseSequenceId(sh):\n",
        "  if (sh[0] == '@'):\n",
        "    return sh.split()[0][1:]\n",
        "       \n",
        "\n",
        "def seqQuality(score_table, st):\n",
        "  acc = 0\n",
        "  for c in st:\n",
        "    acc = acc + score_table[c]\n",
        "  return acc\n",
        "\n",
        "# seqCleaner per il momento implementa un metodo piuttosto rozzo per valutare la\n",
        "# qualità dell'\n",
        "def seqProcessor(rowGroup, st):\n",
        "  score = 0  \n",
        "  groupNumber = rowGroup[0]\n",
        "  rowList = list(rowGroup[1])\n",
        "  # ora abbiamo una lista di 4 elementi, il gruppo di righe\n",
        "  seqHeader = rowList[0][0]\n",
        "  rawSequence = rowList[1][0]\n",
        "  seqScore = rowList[3][0]\n",
        "  score = (seqQuality(scoreTable, rawSequence) / len(rawSequence))\n",
        "\n",
        "  seqId = parseSequenceId(seqHeader)\n",
        "\n",
        "  if (score > 54):\n",
        "    return (groupNumber,(rawSequence, seqId))\n",
        "\n",
        "cleanedSeq = seqGroups.map(lambda r: seqProcessor(r,scoreTable))\n",
        "cleanedSeq = cleanedSeq.filter(lambda x: x != None)\n",
        "#cleanedSeq.collect()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCWpmDrZWOwx"
      },
      "source": [
        "# Otteniamo un RDD delle sole sequenze filtrate al passaggio precedente\n",
        "#seqRdd = cleanedSeq.map(lambda r: r[1][0])\n",
        "seqRdd = cleanedSeq.map(lambda r: (r[1][0],r[1][1]))\n",
        "#seqRdd.collect()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMinsPgJE2FR"
      },
      "source": [
        "# Calcoliamo i k-mer di lunghezza KSIZE dalle sequenze\n",
        "# Per ogni sequenza otteniamo una lista di k-mer che rendiamo in una sola string\n",
        "def singleSeqKmer(l, ksize):\n",
        "  sequence = l.strip()\n",
        "  kmers = []\n",
        "\n",
        "  for i in range(0,len(l)-ksize):\n",
        "    kmers.append(sequence[i:i+ksize+1])\n",
        "\n",
        "  kmerString = ' '.join(kmers)\n",
        "  return kmerString\n",
        "\n",
        "fullKmerSeq = seqRdd.map(lambda kmPair: (singleSeqKmer(kmPair[0],KSIZE),kmPair[1]))\n",
        "#fullKmerSeq.collect()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL4zj3UDHIOt"
      },
      "source": [
        "# Dalla singola stringa andiamo ad effettuarle lo split finale\n",
        "#kmerSplit = fullKmerSeq.map(lambda line: (line[0].split(\" \"),line[1]))\n",
        "kmerSplit = fullKmerSeq.flatMap(lambda line: [(x, line[1]) for x in line[0].split(\" \")])\n",
        "\n",
        "#kmerSplit.collect()\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8oDjXiEZxHY"
      },
      "source": [
        "def occReducer(lAccu, lCur):\n",
        "  return (lAccu[0]+lCur[0],lAccu[1],lAccu[2],lAccu[3]+lCur[3])\n",
        "\n",
        "kmerCounts = kmerSplit.map(lambda singleKmer: (singleKmer[0], (1,singleKmer[0][0:-1],singleKmer[0][1:],[singleKmer[1]]))).reduceByKey(lambda accu, cur: occReducer(accu, cur))\n",
        "kmerCounts.saveAsTextFile(OUTPUT_PATH)\n",
        "\n",
        "# stampiamo le prime 20 entries del RDD\n",
        "kmerCounts.take(20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}